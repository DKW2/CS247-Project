{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe44d2f2-865c-430a-a482-05bff0f8adf5",
   "metadata": {},
   "source": [
    "This notebook searches for the best sampling rate hyperparameters for the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bea0e9-730c-468e-82f6-736f15decf8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 32, 12\n",
      "[2025-03-09 16:13:56,061][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/16-13-55\n",
      "[2025-03-09 16:13:56,063][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=32 logspec.hop_length=12 module.in_features=272 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=32', 'logspec.hop_length=12', 'module.in_features=272', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 16\n",
      "[2025-03-09 17:27:54,089][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/17-27-53\n",
      "[2025-03-09 17:27:54,090][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=32 logspec.hop_length=16 module.in_features=272 +validate=False\n",
      "Testing 32, 20\n",
      "[2025-03-09 18:24:06,964][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/18-24-06\n",
      "[2025-03-09 18:24:06,965][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=32 logspec.hop_length=20 module.in_features=272 +validate=False\n",
      "Testing 64, 12\n",
      "[2025-03-09 19:10:12,267][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/19-10-12\n",
      "[2025-03-09 19:10:12,268][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=12 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=12', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 16\n",
      "[2025-03-09 19:10:22,717][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/19-10-22\n",
      "[2025-03-09 19:10:22,718][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=16 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=16', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 20\n",
      "[2025-03-09 20:10:53,070][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/20-10-52\n",
      "[2025-03-09 20:10:53,071][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=20 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=20', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 12\n",
      "[2025-03-09 20:58:06,417][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/20-58-06\n",
      "[2025-03-09 20:58:06,419][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=12 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=12', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 16\n",
      "[2025-03-09 20:58:17,747][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/20-58-17\n",
      "[2025-03-09 20:58:17,748][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=16 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=16', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 20\n",
      "[2025-03-09 20:58:28,088][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/20-58-27\n",
      "[2025-03-09 20:58:28,089][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=20 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=20', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling rate seems to be based on LogSpectrogram, where hop_length downsamples by dividing 2kHz and FFT window affects the number of frequency bins\n",
    "# Lets try grid searching through them\n",
    "# Do 40 epochs as this is gonna take a bit\n",
    "ffts = [32, 64, 96]\n",
    "hops = [12, 16, 20] # Lower hop_length = higher frequency\n",
    "for fft in ffts:\n",
    "    for hop in hops:\n",
    "        in_features = (fft // 2 + 1) * 16 # in_features has to be changed to adjust to the sampling changes.\n",
    "        print( f\"Testing {fft}, {hop}\" )\n",
    "        !python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          logspec.n_fft={fft} \\\n",
    "          logspec.hop_length={hop} \\\n",
    "          module.in_features={in_features} \\\n",
    "          +validate=False \\\n",
    "          --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68f87f-d95e-4b10-8a2a-725fb57cd149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 32 26.41\n",
    "# 16 32 23.57\n",
    "# 20 32 20.8\n",
    "# 12 64 ???\n",
    "# 16 64 21.44\n",
    "# 20 64 18.56\n",
    "# 12 96 ???\n",
    "# 16 96 ???\n",
    "# 20 96 ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a35453-1974-4467-8829-ed311b45cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 12, 64\n",
      "[2025-03-09 21:34:39,582][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/21-34-39\n",
      "[2025-03-09 21:34:39,583][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=12 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=12', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 12\n",
      "[2025-03-09 22:57:19,670][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/22-57-19\n",
      "[2025-03-09 22:57:19,671][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=12 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=12', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 16\n",
      "[2025-03-09 22:57:30,239][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-09/22-57-30\n",
      "[2025-03-09 22:57:30,240][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=16 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=16', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 20\n",
      "[2025-03-10 00:02:32,987][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/00-02-32\n",
      "[2025-03-10 00:02:32,988][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=20 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=20', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( \"Testing 12, 64\" )\n",
    "!python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          logspec.n_fft=64 \\\n",
    "          logspec.hop_length=12 \\\n",
    "          module.in_features=528 \\\n",
    "          +validate=False \\\n",
    "          --multirun\n",
    "\n",
    "hops = [12, 16, 20] # Lower hop_length = higher frequency\n",
    "for hop in hops:\n",
    "    in_features = (96 // 2 + 1) * 16 # in_features has to be changed to adjust to the sampling changes.\n",
    "    print( f\"Testing 96, {hop}\" )\n",
    "    !python3.10 -m emg2qwerty.train \\\n",
    "      user=\"single_user\" \\\n",
    "      trainer.accelerator=gpu trainer.devices=1 \\\n",
    "      logspec.n_fft=96 \\\n",
    "      logspec.hop_length={hop} \\\n",
    "      module.in_features={in_features} \\\n",
    "      +validate=False \\\n",
    "      --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba297a8-84d7-479a-8c7c-fe7967b6c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 12 24.3\n",
    "# 96 12 ???\n",
    "# 96 16 18.94\n",
    "# 96 20 20.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0348be3f-5dc9-4897-af8c-814537c27229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 96, 12\n",
      "[2025-03-10 01:03:59,554][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/01-03-59\n",
      "[2025-03-10 01:03:59,555][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=96 logspec.hop_length=12 module.in_features=784 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=96', 'logspec.hop_length=12', 'module.in_features=784', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last one, batch_size too large\n",
    "print( f\"Testing 96, 12\" )\n",
    "!python3.10 -m emg2qwerty.train \\\n",
    "  user=\"single_user\" \\\n",
    "  trainer.accelerator=gpu trainer.devices=1 \\\n",
    "  logspec.n_fft=96 \\\n",
    "  logspec.hop_length=12 \\\n",
    "  module.in_features=784 \\\n",
    "  +validate=False \\\n",
    "  --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e02be-e67c-4c77-8d9e-d53435ec8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac6d372-f32d-4c5a-b96a-58c2fff53933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 32 26.41\n",
    "# 16 32 23.57\n",
    "# 20 32 20.8\n",
    "# 12 64 24.3\n",
    "# 16 64 21.44\n",
    "# 20 64 18.56\n",
    "# 12 96 24.77\n",
    "# 16 96 18.94\n",
    "# 20 96 20.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb58994-6017-42c8-a087-af741c35ea90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 48, 18\n",
      "[2025-03-10 02:48:49,065][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/02-48-48\n",
      "[2025-03-10 02:48:49,066][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=48 logspec.hop_length=18 module.in_features=400 +validate=False\n",
      "Testing 48, 20\n",
      "[2025-03-10 03:42:51,541][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/03-42-51\n",
      "[2025-03-10 03:42:51,542][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=48 logspec.hop_length=20 module.in_features=400 +validate=False\n",
      "Testing 48, 22\n",
      "[2025-03-10 04:31:17,052][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/04-31-16\n",
      "[2025-03-10 04:31:17,053][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=48 logspec.hop_length=22 module.in_features=400 +validate=False\n",
      "Testing 48, 24\n",
      "[2025-03-10 05:15:54,404][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/05-15-54\n",
      "[2025-03-10 05:15:54,406][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=48 logspec.hop_length=24 module.in_features=400 +validate=False\n",
      "Testing 64, 18\n",
      "[2025-03-10 05:57:07,564][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/05-57-07\n",
      "[2025-03-10 05:57:07,566][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=18 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=18', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 20\n",
      "[2025-03-10 06:51:48,699][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/06-51-48\n",
      "[2025-03-10 06:51:48,700][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=20 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=20', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 22\n",
      "[2025-03-10 07:41:24,485][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/07-41-24\n",
      "[2025-03-10 07:41:24,486][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=22 module.in_features=528 +validate=False\n",
      "Testing 64, 24\n",
      "[2025-03-10 08:26:45,908][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/08-26-45\n",
      "[2025-03-10 08:26:45,909][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=24 module.in_features=528 +validate=False\n",
      "Testing 80, 18\n",
      "[2025-03-10 09:08:33,105][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/09-08-32\n",
      "[2025-03-10 09:08:33,106][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=80 logspec.hop_length=18 module.in_features=656 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=80', 'logspec.hop_length=18', 'module.in_features=656', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 20\n",
      "[2025-03-10 10:04:58,320][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/10-04-58\n",
      "[2025-03-10 10:04:58,321][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=80 logspec.hop_length=20 module.in_features=656 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=80', 'logspec.hop_length=20', 'module.in_features=656', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 22\n",
      "[2025-03-10 10:56:12,130][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/10-56-11\n",
      "[2025-03-10 10:56:12,131][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=80 logspec.hop_length=22 module.in_features=656 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=80', 'logspec.hop_length=22', 'module.in_features=656', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 24\n",
      "[2025-03-10 11:42:43,739][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-10/11-42-43\n",
      "[2025-03-10 11:42:43,741][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=80 logspec.hop_length=24 module.in_features=656 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=80', 'logspec.hop_length=24', 'module.in_features=656', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Smaller Grid Search\n",
    "ffts = [48, 64, 80]\n",
    "hops = [18, 20, 22, 24] # Lower hop_length = higher frequency\n",
    "for fft in ffts:\n",
    "    for hop in hops:\n",
    "        in_features = (fft // 2 + 1) * 16 # in_features has to be changed to adjust to the sampling changes.\n",
    "        print( f\"Testing {fft}, {hop}\" )\n",
    "        !python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          logspec.n_fft={fft} \\\n",
    "          logspec.hop_length={hop} \\\n",
    "          module.in_features={in_features} \\\n",
    "          +validate=False \\\n",
    "          --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd9b38-9da7-4371-bd46-01b4120d9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48 18 25.47\n",
    "# 48 20 20.71\n",
    "# 48 22 20.89\n",
    "# 48 24 23.39\n",
    "# 64 18 20.16\n",
    "# 64 20 17.88\n",
    "# 64 22 19.83\n",
    "# 64 24 17.72 ***\n",
    "# 80 18 22.13\n",
    "# 80 20 23.57\n",
    "# 80 22 18.34\n",
    "# 80 24 19.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77f6395-85df-47c4-b501-b50b713b105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-11 20:47:54,313][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-11/20-47-54\n",
      "[2025-03-11 20:47:54,314][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 logspec.n_fft=64 logspec.hop_length=16 module.in_features=528 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'logspec.n_fft=64', 'logspec.hop_length=16', 'module.in_features=528', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a full model with 64 fft window and 24 hop length\n",
    "!python3.10 -m emg2qwerty.train \\\n",
    "      user=\"single_user\" \\\n",
    "      trainer.accelerator=gpu trainer.devices=1 \\\n",
    "      logspec.n_fft=64 \\\n",
    "      logspec.hop_length=16 \\\n",
    "      module.in_features=528 \\\n",
    "      +validate=False \\\n",
    "      --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e744d-6fa6-4d7a-8e9d-6d44ea8e7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final validation: 15.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f14b54-aced-46be-bc32-1ccfd1f51bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-11 00:39:47,608][__main__][INFO] - \n",
      "Config:\n",
      "user: single_user\n",
      "dataset:\n",
      "  train:\n",
      "  - user: 89335547\n",
      "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  val:\n",
      "  - user: 89335547\n",
      "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  test:\n",
      "  - user: 89335547\n",
      "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  root: ${hydra:runtime.cwd}/data\n",
      "to_tensor:\n",
      "  _target_: emg2qwerty.transforms.ToTensor\n",
      "  fields:\n",
      "  - emg_left\n",
      "  - emg_right\n",
      "band_rotation:\n",
      "  _target_: emg2qwerty.transforms.ForEach\n",
      "  transform:\n",
      "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
      "    offsets:\n",
      "    - -1\n",
      "    - 0\n",
      "    - 1\n",
      "temporal_jitter:\n",
      "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
      "  max_offset: 120\n",
      "logspec:\n",
      "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
      "  n_fft: 64\n",
      "  hop_length: 24\n",
      "specaug:\n",
      "  _target_: emg2qwerty.transforms.SpecAugment\n",
      "  n_time_masks: 3\n",
      "  time_mask_param: 25\n",
      "  n_freq_masks: 2\n",
      "  freq_mask_param: 4\n",
      "transforms:\n",
      "  train:\n",
      "  - ${to_tensor}\n",
      "  - ${band_rotation}\n",
      "  - ${temporal_jitter}\n",
      "  - ${logspec}\n",
      "  - ${specaug}\n",
      "  val:\n",
      "  - ${to_tensor}\n",
      "  - ${logspec}\n",
      "  test: ${transforms.val}\n",
      "module:\n",
      "  _target_: emg2qwerty.lightning.TDSRecurrentModule\n",
      "  in_features: 528\n",
      "  mlp_features:\n",
      "  - 384\n",
      "  model_type: lstm\n",
      "  hidden_features: 160\n",
      "  num_layers: 5\n",
      "  bidirectional: true\n",
      "  dropout: 0.2\n",
      "datamodule:\n",
      "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
      "  window_length: 8000\n",
      "  padding:\n",
      "  - 1800\n",
      "  - 200\n",
      "optimizer:\n",
      "  _target_: torch.optim.Adam\n",
      "  lr: 0.001\n",
      "lr_scheduler:\n",
      "  scheduler:\n",
      "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
      "    warmup_epochs: 10\n",
      "    max_epochs: ${trainer.max_epochs}\n",
      "    warmup_start_lr: 1.0e-08\n",
      "    eta_min: 1.0e-06\n",
      "  interval: epoch\n",
      "decoder:\n",
      "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
      "seed: 1501\n",
      "batch_size: 16\n",
      "num_workers: 4\n",
      "train: false\n",
      "checkpoint: logs/2025-03-10/12-54-08/best.ckpt\n",
      "monitor_metric: val/CER\n",
      "monitor_mode: min\n",
      "trainer:\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  num_nodes: 1\n",
      "  max_epochs: 150\n",
      "  default_root_dir: ${hydra:runtime.output_dir}\n",
      "callbacks:\n",
      "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
      "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
      "  monitor: ${monitor_metric}\n",
      "  mode: ${monitor_mode}\n",
      "  save_last: true\n",
      "  verbose: true\n",
      "validate: false\n",
      "\n",
      "Global seed set to 1501\n",
      "[2025-03-11 00:39:47,609][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSRecurrentModule', 'in_features': 528, 'mlp_features': [384], 'model_type': 'lstm', 'hidden_features': 160, 'num_layers': 5, 'bidirectional': True, 'dropout': 0.2}\n",
      "[2025-03-11 00:39:47,654][__main__][INFO] - Loading module from checkpoint logs/2025-03-10/12-54-08/best.ckpt\n",
      "[2025-03-11 00:39:48,266][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/fortemir/projects/emg2qwerty/logs/2025-03-11/00-39-47/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Testing DataLoader 0: 100%|| 1/1 [00:09<00:00,  9.29s/it]\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test/CER            17.354658126831055\n",
      "        test/DER            2.0747785568237305\n",
      "        test/IER            1.7289820909500122\n",
      "        test/SER            13.550896644592285\n",
      "        test/loss           0.7348927855491638\n",
      "\n",
      "{'val_metrics': {},\n",
      " 'test_metrics': [{'test/loss': 0.7348927855491638,\n",
      "                   'test/CER': 17.354658126831055,\n",
      "                   'test/IER': 1.7289820909500122,\n",
      "                   'test/DER': 2.0747785568237305,\n",
      "                   'test/SER': 13.550896644592285}],\n",
      " 'best_checkpoint': ''}\n"
     ]
    }
   ],
   "source": [
    "# Test final model\n",
    "!python3.10 -m emg2qwerty.train \\\n",
    "  user=\"single_user\" \\\n",
    "  checkpoint=\"logs/2025-03-10/12-54-08/best.ckpt\" \\\n",
    "  train=False trainer.accelerator=gpu \\\n",
    "  decoder=ctc_greedy \\\n",
    "  hydra.launcher.mem_gb=64 \\\n",
    "  logspec.n_fft=64 \\\n",
    "  logspec.hop_length=24 \\\n",
    "  module.in_features=528 \\\n",
    "  +validate=False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
