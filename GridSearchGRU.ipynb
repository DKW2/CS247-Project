{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a148a2-dd17-49b1-a819-7f29b2052632",
   "metadata": {},
   "source": [
    "This notebook did a hyperparameters gridsearch for GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50312e09-0868-484f-a109-131122c69115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some basic grid search for GRU\n",
    "import time\n",
    "hidden_feature_nums = [16,32,64,128]\n",
    "num_layers = [3, 5, 8, 10]\n",
    "bidirectional = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d42b172-c555-4cb8-aa71-4ccd4e709191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 16, 3, True\n",
      "[2025-03-06 11:34:18,610][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/11-34-18\n",
      "[2025-03-06 11:34:18,611][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=16 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=16', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 3, False\n",
      "[2025-03-06 11:51:51,288][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/11-51-51\n",
      "[2025-03-06 11:51:51,289][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=16 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=16', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 5, True\n",
      "[2025-03-06 12:09:22,772][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/12-09-22\n",
      "[2025-03-06 12:09:22,773][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=16 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=16', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 5, False\n",
      "[2025-03-06 12:27:03,309][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/12-27-03\n",
      "[2025-03-06 12:27:03,310][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=16 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=16', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 8, True\n",
      "[2025-03-06 12:44:34,888][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/12-44-34\n",
      "[2025-03-06 12:44:34,889][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=16 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=16', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 8, False\n",
      "[2025-03-06 13:02:21,389][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/13-02-21\n",
      "[2025-03-06 13:02:21,391][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=16 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=16', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 10, True\n",
      "[2025-03-06 13:20:04,103][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/13-20-03\n",
      "[2025-03-06 13:20:04,104][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=16 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=16', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 16, 10, False\n",
      "[2025-03-06 13:37:56,769][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/13-37-56\n",
      "[2025-03-06 13:37:56,770][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=16 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=16', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 3, True\n",
      "[2025-03-06 13:55:41,308][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/13-55-41\n",
      "[2025-03-06 13:55:41,309][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=32 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=32', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 3, False\n",
      "[2025-03-06 14:13:13,880][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/14-13-13\n",
      "[2025-03-06 14:13:13,882][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=32 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=32', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 5, True\n",
      "[2025-03-06 14:30:37,474][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/14-30-37\n",
      "[2025-03-06 14:30:37,475][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=32 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=32', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 5, False\n",
      "[2025-03-06 14:48:25,940][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/14-48-25\n",
      "[2025-03-06 14:48:25,941][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=32 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=32', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 8, True\n",
      "[2025-03-06 15:05:56,475][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/15-05-56\n",
      "[2025-03-06 15:05:56,476][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=32 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=32', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 8, False\n",
      "[2025-03-06 15:23:45,090][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/15-23-44\n",
      "[2025-03-06 15:23:45,091][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=32 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=32', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 10, True\n",
      "[2025-03-06 15:41:19,591][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/15-41-19\n",
      "[2025-03-06 15:41:19,592][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=32 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=32', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 32, 10, False\n",
      "[2025-03-06 15:59:09,116][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/15-59-08\n",
      "[2025-03-06 15:59:09,118][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=32 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=32', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 3, True\n",
      "[2025-03-06 16:16:49,638][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/16-16-49\n",
      "[2025-03-06 16:16:49,640][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=64 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=64', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 3, False\n",
      "[2025-03-06 16:34:30,147][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/16-34-30\n",
      "[2025-03-06 16:34:30,148][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=64 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=64', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 5, True\n",
      "[2025-03-06 16:51:56,750][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/16-51-56\n",
      "[2025-03-06 16:51:56,751][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=64 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=64', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 5, False\n",
      "[2025-03-06 17:10:00,443][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/17-10-00\n",
      "[2025-03-06 17:10:00,444][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=64 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=64', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 8, True\n",
      "[2025-03-06 17:28:45,341][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/17-28-45\n",
      "[2025-03-06 17:28:45,342][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=64 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=64', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 8, False\n",
      "[2025-03-06 17:55:51,796][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/17-55-51\n",
      "[2025-03-06 17:55:51,797][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=64 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=64', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 10, True\n",
      "[2025-03-06 18:15:17,726][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/18-15-17\n",
      "[2025-03-06 18:15:17,728][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=64 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=64', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 10, False\n",
      "[2025-03-06 18:36:47,593][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/18-36-47\n",
      "[2025-03-06 18:36:47,594][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=64 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=64', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 3, True\n",
      "[2025-03-06 18:56:18,514][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/18-56-18\n",
      "[2025-03-06 18:56:18,515][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=128 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=128', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 3, False\n",
      "[2025-03-06 19:16:14,416][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/19-16-14\n",
      "[2025-03-06 19:16:14,418][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=128 module.num_layers=3 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=128', 'module.num_layers=3', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 5, True\n",
      "[2025-03-06 19:34:53,129][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/19-34-52\n",
      "[2025-03-06 19:34:53,130][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=128 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=128', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 5, False\n",
      "[2025-03-06 19:55:47,829][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/19-55-47\n",
      "[2025-03-06 19:55:47,830][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=128 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=128', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 8, True\n",
      "[2025-03-06 20:13:42,441][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/20-13-42\n",
      "[2025-03-06 20:13:42,442][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=128 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=128', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 8, False\n",
      "[2025-03-06 20:39:25,414][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/20-39-25\n",
      "[2025-03-06 20:39:25,415][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=128 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=128', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 10, True\n",
      "[2025-03-06 20:57:56,029][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/20-57-55\n",
      "[2025-03-06 20:57:56,031][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=True module.hidden_features=128 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=True', 'module.hidden_features=128', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 10, False\n",
      "[2025-03-06 21:26:47,330][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-06/21-26-47\n",
      "[2025-03-06 21:26:47,331][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.bidirectional=False module.hidden_features=128 module.num_layers=10 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.bidirectional=False', 'module.hidden_features=128', 'module.num_layers=10', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for hidden_dim in hidden_feature_nums:\n",
    "    for num_layer in num_layers:\n",
    "        for bi in bidirectional:\n",
    "            print( f\"Testing {hidden_dim}, {num_layer}, {bi}\" )\n",
    "            !python3.10 -m emg2qwerty.train \\\n",
    "              user=\"single_user\" \\\n",
    "              trainer.accelerator=gpu trainer.devices=1 \\\n",
    "              module.bidirectional={bi} \\\n",
    "              module.hidden_features={hidden_dim} \\\n",
    "              module.num_layers={num_layer} \\\n",
    "              module.dropout=0.1 \\\n",
    "              +validate=False \\\n",
    "              --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f03d5-4426-49fb-9efd-fd6992d87055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results:\n",
    "# 16, 3, bidirectional: 60.96\n",
    "# 16, 3, no: 92.8\n",
    "# 16, 5, b: 45\n",
    "# 16, 5, n: 78\n",
    "# 16, 8, b: 56\n",
    "# 16, 8, n: 89\n",
    "# 16, 10, b: 62\n",
    "# 16, 10, n: 79\n",
    "# 32, 3, b: 32.98\n",
    "# 32, 3, n: 58\n",
    "# 32, 5, b: 30.97\n",
    "# 32, 5, n: 44.57\n",
    "# 32, 8, b: 29\n",
    "# 32, 8, n: 60.7\n",
    "# 32, 10, b: 31.6\n",
    "# 32, 10, n: 76\n",
    "# 64, 3, b: 22.88\n",
    "# 64, 3, n: 38.5\n",
    "# 64, 5, b: 22.72\n",
    "# 64, 5, n: 33.3\n",
    "# 64, 8, b: 19.96\n",
    "# 64, 8, n: 38.12\n",
    "# 64, 10, b: 26\n",
    "# 64, 10, n: 41\n",
    "# 128, 3, b: 18.58\n",
    "# 128, 3, n: 28.88\n",
    "# 128, 5, b: 17.05 ***\n",
    "# 128, 5, n: 26.18\n",
    "# 128, 8, b: 21.44\n",
    "# 128, 8, n: 33.29\n",
    "# 128, 10, b: 22.24\n",
    "# 128, 10, n: 98.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fe0235-93ce-47a7-ba6b-f0d9dfcec550",
   "metadata": {},
   "source": [
    "# Results\n",
    "128 hidden_dim, 5 layers, bidirectional performed the best\n",
    "\n",
    "Note: Bidirectional always performs better, sweet spot between 64 and 128 hidden_dim and 5-8 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a76fcf-dc1e-46ce-8210-bba160f4a478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 64, 7\n",
      "[2025-03-07 00:54:23,513][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/00-54-23\n",
      "[2025-03-07 00:54:23,514][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=64 module.num_layers=7 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=64', 'module.num_layers=7', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 64, 8\n",
      "[2025-03-07 01:13:32,185][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/01-13-32\n",
      "[2025-03-07 01:13:32,186][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=64 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=64', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 5\n",
      "[2025-03-07 01:33:35,895][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/01-33-35\n",
      "[2025-03-07 01:33:35,896][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=80 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=80', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 6\n",
      "[2025-03-07 01:53:03,164][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/01-53-03\n",
      "[2025-03-07 01:53:03,165][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=80 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=80', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 7\n",
      "[2025-03-07 02:13:58,621][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/02-13-58\n",
      "[2025-03-07 02:13:58,622][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=80 module.num_layers=7 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=80', 'module.num_layers=7', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 80, 8\n",
      "[2025-03-07 02:36:08,111][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/02-36-07\n",
      "[2025-03-07 02:36:08,112][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=80 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=80', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 5\n",
      "[2025-03-07 02:58:59,552][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/02-58-59\n",
      "[2025-03-07 02:58:59,553][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=96 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=96', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 6\n",
      "[2025-03-07 03:19:26,982][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/03-19-26\n",
      "[2025-03-07 03:19:26,983][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=96 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=96', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 7\n",
      "[2025-03-07 03:40:42,344][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/03-40-42\n",
      "[2025-03-07 03:40:42,346][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=96 module.num_layers=7 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=96', 'module.num_layers=7', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 96, 8\n",
      "[2025-03-07 04:03:02,707][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/04-03-02\n",
      "[2025-03-07 04:03:02,709][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=96 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=96', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 112, 5\n",
      "[2025-03-07 04:26:31,483][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/04-26-31\n",
      "[2025-03-07 04:26:31,484][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 112, 6\n",
      "[2025-03-07 04:46:52,181][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/04-46-52\n",
      "[2025-03-07 04:46:52,182][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 112, 7\n",
      "[2025-03-07 05:08:33,880][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/05-08-33\n",
      "[2025-03-07 05:08:33,881][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=7 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=7', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 112, 8\n",
      "[2025-03-07 05:31:49,719][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/05-31-49\n",
      "[2025-03-07 05:31:49,720][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 5\n",
      "[2025-03-07 05:56:40,680][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/05-56-40\n",
      "[2025-03-07 05:56:40,681][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 6\n",
      "[2025-03-07 06:17:37,400][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/06-17-37\n",
      "[2025-03-07 06:17:37,401][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 7\n",
      "[2025-03-07 06:40:04,166][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/06-40-04\n",
      "[2025-03-07 06:40:04,167][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=7 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=7', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 8\n",
      "[2025-03-07 07:04:10,097][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/07-04-09\n",
      "[2025-03-07 07:04:10,098][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=8 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=8', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do a smaller search!\n",
    "hidden_feature_nums = [64, 80, 96, 112, 128]\n",
    "num_layers = [5, 6, 7, 8]\n",
    "for hidden_dim in hidden_feature_nums:\n",
    "    for num_layer in num_layers:\n",
    "        if( hidden_dim == 64 and (num_layer == 5 or num_layer == 6) ):\n",
    "            continue\n",
    "        print( f\"Testing {hidden_dim}, {num_layer}\" )\n",
    "        !python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          module.hidden_features={hidden_dim} \\\n",
    "          module.num_layers={num_layer} \\\n",
    "          module.dropout=0.1 \\\n",
    "          +validate=False \\\n",
    "          --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e2447c-0222-4b4c-8993-4c79cbc68f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64, 5, 22.73\n",
    "# 64, 6, 20.65\n",
    "# 64, 7, 21.02\n",
    "# 64, 8, 19.96\n",
    "# 80, 5, 19.49\n",
    "# 80, 6, 18.91\n",
    "# 80, 7, 19.49\n",
    "# 80, 8, 21.15\n",
    "# 96, 5, 18.87\n",
    "# 96, 6, 18.23\n",
    "# 96, 7, 19.49\n",
    "# 96, 8, 21.26\n",
    "# 112, 5, 17.61\n",
    "# 112, 6, 17.72\n",
    "# 112, 7, 19.56\n",
    "# 112, 8, 19.98\n",
    "# 128, 5, 17.05 ***\n",
    "# 128, 6, 20.09\n",
    "# 128, 7, 18.07\n",
    "# 128, 8, 21.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a64519-c542-4637-977a-2b71e62f2250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 112, 4\n",
      "[2025-03-07 11:44:44,604][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/11-44-44\n",
      "[2025-03-07 11:44:44,605][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 112, 5\n",
      "[2025-03-07 12:04:42,280][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/12-04-42\n",
      "[2025-03-07 12:04:42,281][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 112, 6\n",
      "[2025-03-07 12:25:02,011][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/12-25-01\n",
      "[2025-03-07 12:25:02,013][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=112 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=112', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 120, 4\n",
      "[2025-03-07 12:46:42,663][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/12-46-42\n",
      "[2025-03-07 12:46:42,664][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=120 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=120', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 120, 5\n",
      "[2025-03-07 13:06:05,228][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/13-06-05\n",
      "[2025-03-07 13:06:05,229][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=120 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=120', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 120, 6\n",
      "[2025-03-07 13:26:43,884][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/13-26-43\n",
      "[2025-03-07 13:26:43,885][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=120 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=120', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 4\n",
      "[2025-03-07 13:48:49,678][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/13-48-49\n",
      "[2025-03-07 13:48:49,679][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 5\n",
      "[2025-03-07 14:08:24,330][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/14-08-24\n",
      "[2025-03-07 14:08:24,331][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 128, 6\n",
      "[2025-03-07 14:29:17,000][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/14-29-16\n",
      "[2025-03-07 14:29:17,002][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=128 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=128', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 136, 4\n",
      "[2025-03-07 14:52:44,978][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/14-52-44\n",
      "[2025-03-07 14:52:44,979][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 136, 5\n",
      "[2025-03-07 15:23:36,502][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/15-23-36\n",
      "[2025-03-07 15:23:36,504][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 136, 6\n",
      "[2025-03-07 15:57:07,976][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/15-57-07\n",
      "[2025-03-07 15:57:07,977][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 148, 4\n",
      "[2025-03-07 16:33:06,583][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/16-33-06\n",
      "[2025-03-07 16:33:06,584][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=148 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=148', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 148, 5\n",
      "[2025-03-07 17:02:03,791][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/17-02-03\n",
      "[2025-03-07 17:02:03,792][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=148 module.num_layers=5 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=148', 'module.num_layers=5', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "Testing 148, 6\n",
      "[2025-03-07 17:34:57,168][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/17-34-57\n",
      "[2025-03-07 17:34:57,169][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=148 module.num_layers=6 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=148', 'module.num_layers=6', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 128, 5 still does the best, Do a smaller grid search :3\n",
    "# Do a smaller search!\n",
    "hidden_feature_nums = [112,120,128,136,148]\n",
    "num_layers = [4, 5, 6]\n",
    "for hidden_dim in hidden_feature_nums:\n",
    "    for num_layer in num_layers:\n",
    "        print( f\"Testing {hidden_dim}, {num_layer}\" )\n",
    "        !python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          module.hidden_features={hidden_dim} \\\n",
    "          module.num_layers={num_layer} \\\n",
    "          module.dropout=0.1 \\\n",
    "          +validate=False \\\n",
    "          --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abec4a-620e-44e9-89fe-669e2a729f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 112, 4, 18.52\n",
    "# 112, 5, 17.61\n",
    "# 112, 6, 17.72\n",
    "# 120, 4, 17.94\n",
    "# 120, 5, 17.41\n",
    "# 120, 6, 18.70\n",
    "# 128, 4, 17.74\n",
    "# 128, 5, 17.05\n",
    "# 128, 6, 20.09\n",
    "# 136, 4, 16.93\n",
    "# 136, 5, 17.39\n",
    "# 136, 6, 18.68\n",
    "# 148, 4, 16.68 ***\n",
    "# 148, 5, 17.23\n",
    "# 148, 6, 17.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e8d1893-635c-46c4-9514-95e7c14eba44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-07 18:12:32,268][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/18-12-32\n",
      "[2025-03-07 18:12:32,269][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "[2025-03-07 18:42:58,712][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/18-42-58\n",
      "[2025-03-07 18:42:58,713][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "[2025-03-07 19:13:00,164][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/19-13-00\n",
      "[2025-03-07 19:13:00,165][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0.2 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0.2', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "[2025-03-07 19:42:30,452][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/19-42-30\n",
      "[2025-03-07 19:42:30,454][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0.3 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0.3', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "[2025-03-07 20:13:09,960][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/20-13-09\n",
      "[2025-03-07 20:13:09,962][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0.4 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0.4', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n",
      "[2025-03-07 20:44:05,446][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/20-44-05\n",
      "[2025-03-07 20:44:05,447][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=136 module.num_layers=4 module.dropout=0.5 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=136', 'module.num_layers=4', 'module.dropout=0.5', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pretty good CER, now lets try optimizing 136, 4, bidirectional with dropout\n",
    "dropout = [0, 0.1,0.2,0.3,0.4,0.5]\n",
    "for drop in dropout:\n",
    "    !python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          module.hidden_features=148 \\\n",
    "          module.num_layers=4 \\\n",
    "          module.dropout={drop} \\\n",
    "          +validate=False \\\n",
    "          --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbeaf12e-154a-4170-99d6-1dde13a6535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 17.04\n",
    "# 0.1, 16.93\n",
    "# 0.2, 17.86\n",
    "# 0.3, 18.99\n",
    "# 0.4, 19.27\n",
    "# 0.5, 22.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5bbd243-2ec5-453a-85af-595c436deddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-07 23:04:38,783][HYDRA] Submitit 'local' sweep output dir : logs/2025-03-07/23-04-38\n",
      "[2025-03-07 23:04:38,784][HYDRA] \t#0 : user=single_user trainer.accelerator=gpu trainer.devices=1 module.hidden_features=148 module.num_layers=4 module.dropout=0.1 +validate=False\n",
      "Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'module.hidden_features=148', 'module.num_layers=4', 'module.dropout=0.1', '+validate=False']\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 466, in <lambda>\n",
      "    lambda: hydra.multirun(\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 162, in multirun\n",
      "    ret = sweeper.sweep(arguments=task_overrides)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/_internal/core_plugins/basic_sweeper.py\", line 181, in sweep\n",
      "    _ = r.return_value\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
      "    data = pin_memory(data, device)\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
      "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
      "  File \"/home/fortemir/.local/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
      "    return data.pin_memory(device)\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets train the best GRU model with the parameters we found!\n",
    "!python3.10 -m emg2qwerty.train \\\n",
    "          user=\"single_user\" \\\n",
    "          trainer.accelerator=gpu trainer.devices=1 \\\n",
    "          module.hidden_features=148 \\\n",
    "          module.num_layers=4 \\\n",
    "          module.dropout=0.1 \\\n",
    "          +validate=False \\\n",
    "          --multirun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7991b3d4-4bff-4f31-8cf4-7e832a4bacc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-11 00:29:53,112][__main__][INFO] - \n",
      "Config:\n",
      "user: single_user\n",
      "dataset:\n",
      "  train:\n",
      "  - user: 89335547\n",
      "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  - user: 89335547\n",
      "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  val:\n",
      "  - user: 89335547\n",
      "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  test:\n",
      "  - user: 89335547\n",
      "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
      "  root: ${hydra:runtime.cwd}/data\n",
      "to_tensor:\n",
      "  _target_: emg2qwerty.transforms.ToTensor\n",
      "  fields:\n",
      "  - emg_left\n",
      "  - emg_right\n",
      "band_rotation:\n",
      "  _target_: emg2qwerty.transforms.ForEach\n",
      "  transform:\n",
      "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
      "    offsets:\n",
      "    - -1\n",
      "    - 0\n",
      "    - 1\n",
      "temporal_jitter:\n",
      "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
      "  max_offset: 120\n",
      "logspec:\n",
      "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
      "  n_fft: 64\n",
      "  hop_length: 16\n",
      "specaug:\n",
      "  _target_: emg2qwerty.transforms.SpecAugment\n",
      "  n_time_masks: 3\n",
      "  time_mask_param: 25\n",
      "  n_freq_masks: 2\n",
      "  freq_mask_param: 4\n",
      "transforms:\n",
      "  train:\n",
      "  - ${to_tensor}\n",
      "  - ${band_rotation}\n",
      "  - ${temporal_jitter}\n",
      "  - ${logspec}\n",
      "  - ${specaug}\n",
      "  val:\n",
      "  - ${to_tensor}\n",
      "  - ${logspec}\n",
      "  test: ${transforms.val}\n",
      "module:\n",
      "  _target_: emg2qwerty.lightning.TDSRecurrentModule\n",
      "  in_features: 528\n",
      "  mlp_features:\n",
      "  - 384\n",
      "  model_type: lstm\n",
      "  hidden_features: 148\n",
      "  num_layers: 4\n",
      "  bidirectional: true\n",
      "  dropout: 0.1\n",
      "datamodule:\n",
      "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
      "  window_length: 8000\n",
      "  padding:\n",
      "  - 1800\n",
      "  - 200\n",
      "optimizer:\n",
      "  _target_: torch.optim.Adam\n",
      "  lr: 0.001\n",
      "lr_scheduler:\n",
      "  scheduler:\n",
      "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
      "    warmup_epochs: 10\n",
      "    max_epochs: ${trainer.max_epochs}\n",
      "    warmup_start_lr: 1.0e-08\n",
      "    eta_min: 1.0e-06\n",
      "  interval: epoch\n",
      "decoder:\n",
      "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
      "seed: 1501\n",
      "batch_size: 16\n",
      "num_workers: 4\n",
      "train: false\n",
      "checkpoint: logs/2025-03-07/23-04-38/best.ckpt\n",
      "monitor_metric: val/CER\n",
      "monitor_mode: min\n",
      "trainer:\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  num_nodes: 1\n",
      "  max_epochs: 150\n",
      "  default_root_dir: ${hydra:runtime.output_dir}\n",
      "callbacks:\n",
      "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
      "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
      "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
      "  monitor: ${monitor_metric}\n",
      "  mode: ${monitor_mode}\n",
      "  save_last: true\n",
      "  verbose: true\n",
      "validate: false\n",
      "\n",
      "Global seed set to 1501\n",
      "[2025-03-11 00:29:53,113][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSRecurrentModule', 'in_features': 528, 'mlp_features': [384], 'model_type': 'lstm', 'hidden_features': 148, 'num_layers': 4, 'bidirectional': True, 'dropout': 0.1}\n",
      "[2025-03-11 00:29:53,153][__main__][INFO] - Loading module from checkpoint logs/2025-03-07/23-04-38/best.ckpt\n",
      "[2025-03-11 00:29:53,191][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/fortemir/projects/emg2qwerty/logs/2025-03-11/00-29-53/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Testing DataLoader 0: 100%|| 1/1 [00:17<00:00, 17.94s/it]\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test/CER            15.236654281616211\n",
      "        test/DER            1.5344716310501099\n",
      "        test/IER             2.679922103881836\n",
      "        test/SER            11.022260665893555\n",
      "        test/loss           0.5765708684921265\n",
      "\n",
      "{'val_metrics': {},\n",
      " 'test_metrics': [{'test/loss': 0.5765708684921265,\n",
      "                   'test/CER': 15.236654281616211,\n",
      "                   'test/IER': 2.679922103881836,\n",
      "                   'test/DER': 1.5344716310501099,\n",
      "                   'test/SER': 11.022260665893555}],\n",
      " 'best_checkpoint': ''}\n"
     ]
    }
   ],
   "source": [
    "# Test final model\n",
    "!python3.10 -m emg2qwerty.train \\\n",
    "  user=\"single_user\" \\\n",
    "  checkpoint=\"logs/2025-03-07/23-04-38/best.ckpt\" \\\n",
    "  train=False trainer.accelerator=gpu \\\n",
    "  decoder=ctc_greedy \\\n",
    "  hydra.launcher.mem_gb=64 \\\n",
    "  module.hidden_features=148 \\\n",
    "  module.num_layers=4 \\\n",
    "  module.dropout=0.1 \\\n",
    "  +validate=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
